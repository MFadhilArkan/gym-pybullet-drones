{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mahendra/anaconda3/envs/TA/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from ray.rllib.agents.ddpg import DDPGTrainer\n",
    "import ray\n",
    "import shared_constants\n",
    "import tensorflow as tf\n",
    "from ray.rllib.contrib.maddpg import MADDPGTrainer\n",
    "from ray.tune import register_env\n",
    "from gym_pybullet_drones.envs.multi_agent_rl.PayloadCoop import PayloadCoop\n",
    "from ray.rllib.agents.callbacks import DefaultCallbacks\n",
    "import shared_constants\n",
    "from gym_pybullet_drones.envs.single_agent_rl.BaseSingleAgentAviary import ActionType, ObservationType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_phase=0\n",
    "class FillInActions(DefaultCallbacks):\n",
    "    def on_train_result(self, trainer, result):\n",
    "        global current_phase\n",
    "        print(\"Manage Curriculum callback called on phase {}\".format(current_phase))\n",
    "        if result[\"episode_reward_mean\"] > 0:\n",
    "            current_phase+=1\n",
    "            trainer.workers.foreach_worker(\n",
    "            lambda ev: ev.foreach_env(\n",
    "                lambda env: env.set_phase(current_phase)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-24 20:06:56,278\tINFO services.py:1173 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] BaseAviary.__init__() loaded parameters from the drone's .urdf:\n",
      "[INFO] m 0.027000, L 0.039700,\n",
      "[INFO] ixx 0.000014, iyy 0.000014, izz 0.000022,\n",
      "[INFO] kf 0.000000, km 0.000000,\n",
      "[INFO] t2w 2.250000, max_speed_kmh 30.000000,\n",
      "[INFO] gnd_eff_coeff 11.368590, prop_radius 0.023135,\n",
      "[INFO] drag_xy_coeff 0.000001, drag_z_coeff 0.000001,\n",
      "[INFO] dw_coeff_1 2267.180000, dw_coeff_2 0.160000, dw_coeff_3 -0.110000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahendra/anaconda3/envs/TA/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import shared_constants\n",
    "from gym_pybullet_drones.envs.single_agent_rl.BaseSingleAgentAviary import ActionType, ObservationType\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "NUM_DRONES =shared_constants.NUM_DRONES\n",
    "ACT = ActionType(shared_constants.ACT)\n",
    "OBS = ObservationType(shared_constants.OBS)\n",
    "temp_env_name = \"this-aviary-v0\" \n",
    "register_env(temp_env_name, lambda _: PayloadCoop(num_drones=NUM_DRONES,\n",
    "                                                    aggregate_phy_steps=shared_constants.AGGR_PHY_STEPS,\n",
    "                                                    obs=OBS,\n",
    "                                                    act=ACT\n",
    "                                                    ))\n",
    "temp_env = PayloadCoop(num_drones=NUM_DRONES,\n",
    "                            aggregate_phy_steps=shared_constants.AGGR_PHY_STEPS,\n",
    "                            obs=OBS,\n",
    "                            act=ACT,\n",
    "                            )\n",
    "action_space = temp_env.action_space[0]\n",
    "observation_space = temp_env.observation_space[0]\n",
    "\n",
    "obs_space_dict = {\n",
    "    \"agent_1\": observation_space,\n",
    "    \"agent_2\": observation_space,\n",
    "}\n",
    "act_space_dict = {\n",
    "    \"agent_1\": action_space,\n",
    "    \"agent_2\": action_space,\n",
    "}\n",
    "\n",
    "#### Config ##################################################\n",
    "config = {\n",
    "    \"env\": temp_env_name,\n",
    "    \"env_config\": {\n",
    "        \"actions_are_logits\": False,\n",
    "    },\n",
    "    \"multiagent\": {\n",
    "        \"policies\": {\n",
    "            \"pol1\": (None, observation_space, action_space, {\n",
    "                \"agent_id\": 0,\n",
    "            }),\n",
    "            \"pol2\": (None, observation_space, action_space, {\n",
    "                \"agent_id\": 1,\n",
    "            }),\n",
    "        },\n",
    "        \"policy_mapping_fn\": lambda x: \"pol1\" if x == 0 else \"pol2\",\n",
    "    },\n",
    "    \"framework\": \"tf\",\n",
    "    \"callbacks\":FillInActions,\n",
    "    \"gamma\": shared_constants.GAMMA,\n",
    "    \"n_step\": shared_constants.N_STEP,\n",
    "    \"num_workers\": 0 + 4,\n",
    "    \"num_envs_per_worker\": 1,\n",
    "    \"batch_mode\": \"complete_episodes\",\n",
    "\n",
    "    \"actor_hiddens\": [64, 64],\n",
    "    \"critic_hiddens\": [64, 64],\n",
    "    \"actor_lr\": shared_constants.LR,\n",
    "    \"critic_lr\": shared_constants.LR,\n",
    "    \"tau\": 0.01,\n",
    "    \"train_batch_size\": 512,\n",
    "    \"learning_starts\": 512 * 10,\n",
    "    \"explore\": False,\n",
    "    'exploration_config': {\"type\": \"OrnsteinUhlenbeckNoise\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15647)\u001b[0m WARNING:tensorflow:From /home/mahendra/anaconda3/envs/TA/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=15647)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=15647)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=15649)\u001b[0m WARNING:tensorflow:From /home/mahendra/anaconda3/envs/TA/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=15649)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=15649)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=15646)\u001b[0m WARNING:tensorflow:From /home/mahendra/anaconda3/envs/TA/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=15646)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=15646)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=15642)\u001b[0m WARNING:tensorflow:From /home/mahendra/anaconda3/envs/TA/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=15642)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=15642)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=15647)\u001b[0m pybullet build time: Dec 23 2020 01:46:51\n",
      "\u001b[2m\u001b[36m(pid=15649)\u001b[0m pybullet build time: Dec 23 2020 01:46:51\n",
      "\u001b[2m\u001b[36m(pid=15649)\u001b[0m /home/mahendra/anaconda3/envs/TA/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=15649)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=15646)\u001b[0m pybullet build time: Dec 23 2020 01:46:51\n",
      "\u001b[2m\u001b[36m(pid=15646)\u001b[0m /home/mahendra/anaconda3/envs/TA/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=15646)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=15642)\u001b[0m pybullet build time: Dec 23 2020 01:46:51\n",
      "\u001b[2m\u001b[36m(pid=15647)\u001b[0m /home/mahendra/anaconda3/envs/TA/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=15647)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=15642)\u001b[0m /home/mahendra/anaconda3/envs/TA/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=15642)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=15647)\u001b[0m WARNING:tensorflow:From /home/mahendra/anaconda3/envs/TA/lib/python3.6/site-packages/ray/rllib/contrib/maddpg/maddpg_policy.py:348: dense (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=15647)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=15647)\u001b[0m Use keras.layers.Dense instead.\n",
      "\u001b[2m\u001b[36m(pid=15647)\u001b[0m WARNING:tensorflow:From /home/mahendra/anaconda3/envs/TA/lib/python3.6/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=15647)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=15647)\u001b[0m Please use `layer.__call__` method instead.\n",
      "\u001b[2m\u001b[36m(pid=15649)\u001b[0m WARNING:tensorflow:From /home/mahendra/anaconda3/envs/TA/lib/python3.6/site-packages/ray/rllib/contrib/maddpg/maddpg_policy.py:348: dense (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=15649)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=15649)\u001b[0m Use keras.layers.Dense instead.\n",
      "\u001b[2m\u001b[36m(pid=15649)\u001b[0m WARNING:tensorflow:From /home/mahendra/anaconda3/envs/TA/lib/python3.6/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=15649)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=15649)\u001b[0m Please use `layer.__call__` method instead.\n",
      "\u001b[2m\u001b[36m(pid=15646)\u001b[0m WARNING:tensorflow:From /home/mahendra/anaconda3/envs/TA/lib/python3.6/site-packages/ray/rllib/contrib/maddpg/maddpg_policy.py:348: dense (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=15646)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=15646)\u001b[0m Use keras.layers.Dense instead.\n",
      "\u001b[2m\u001b[36m(pid=15646)\u001b[0m WARNING:tensorflow:From /home/mahendra/anaconda3/envs/TA/lib/python3.6/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=15646)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=15646)\u001b[0m Please use `layer.__call__` method instead.\n",
      "\u001b[2m\u001b[36m(pid=15642)\u001b[0m WARNING:tensorflow:From /home/mahendra/anaconda3/envs/TA/lib/python3.6/site-packages/ray/rllib/contrib/maddpg/maddpg_policy.py:348: dense (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=15642)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=15642)\u001b[0m Use keras.layers.Dense instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15649)\u001b[0m [INFO] BaseAviary.__init__() loaded parameters from the drone's .urdf:\n",
      "\u001b[2m\u001b[36m(pid=15649)\u001b[0m [INFO] m 0.027000, L 0.039700,\n",
      "\u001b[2m\u001b[36m(pid=15649)\u001b[0m [INFO] ixx 0.000014, iyy 0.000014, izz 0.000022,\n",
      "\u001b[2m\u001b[36m(pid=15649)\u001b[0m [INFO] kf 0.000000, km 0.000000,\n",
      "\u001b[2m\u001b[36m(pid=15649)\u001b[0m [INFO] t2w 2.250000, max_speed_kmh 30.000000,\n",
      "\u001b[2m\u001b[36m(pid=15649)\u001b[0m [INFO] gnd_eff_coeff 11.368590, prop_radius 0.023135,\n",
      "\u001b[2m\u001b[36m(pid=15649)\u001b[0m [INFO] drag_xy_coeff 0.000001, drag_z_coeff 0.000001,\n",
      "\u001b[2m\u001b[36m(pid=15649)\u001b[0m [INFO] dw_coeff_1 2267.180000, dw_coeff_2 0.160000, dw_coeff_3 -0.110000\n",
      "\u001b[2m\u001b[36m(pid=15646)\u001b[0m [INFO] BaseAviary.__init__() loaded parameters from the drone's .urdf:\n",
      "\u001b[2m\u001b[36m(pid=15646)\u001b[0m [INFO] m 0.027000, L 0.039700,\n",
      "\u001b[2m\u001b[36m(pid=15646)\u001b[0m [INFO] ixx 0.000014, iyy 0.000014, izz 0.000022,\n",
      "\u001b[2m\u001b[36m(pid=15646)\u001b[0m [INFO] kf 0.000000, km 0.000000,\n",
      "\u001b[2m\u001b[36m(pid=15646)\u001b[0m [INFO] t2w 2.250000, max_speed_kmh 30.000000,\n",
      "\u001b[2m\u001b[36m(pid=15646)\u001b[0m [INFO] gnd_eff_coeff 11.368590, prop_radius 0.023135,\n",
      "\u001b[2m\u001b[36m(pid=15646)\u001b[0m [INFO] drag_xy_coeff 0.000001, drag_z_coeff 0.000001,\n",
      "\u001b[2m\u001b[36m(pid=15646)\u001b[0m [INFO] dw_coeff_1 2267.180000, dw_coeff_2 0.160000, dw_coeff_3 -0.110000\n",
      "\u001b[2m\u001b[36m(pid=15647)\u001b[0m [INFO] BaseAviary.__init__() loaded parameters from the drone's .urdf:\n",
      "\u001b[2m\u001b[36m(pid=15647)\u001b[0m [INFO] m 0.027000, L 0.039700,\n",
      "\u001b[2m\u001b[36m(pid=15647)\u001b[0m [INFO] ixx 0.000014, iyy 0.000014, izz 0.000022,\n",
      "\u001b[2m\u001b[36m(pid=15647)\u001b[0m [INFO] kf 0.000000, km 0.000000,\n",
      "\u001b[2m\u001b[36m(pid=15647)\u001b[0m [INFO] t2w 2.250000, max_speed_kmh 30.000000,\n",
      "\u001b[2m\u001b[36m(pid=15647)\u001b[0m [INFO] gnd_eff_coeff 11.368590, prop_radius 0.023135,\n",
      "\u001b[2m\u001b[36m(pid=15647)\u001b[0m [INFO] drag_xy_coeff 0.000001, drag_z_coeff 0.000001,\n",
      "\u001b[2m\u001b[36m(pid=15647)\u001b[0m [INFO] dw_coeff_1 2267.180000, dw_coeff_2 0.160000, dw_coeff_3 -0.110000\n",
      "\u001b[2m\u001b[36m(pid=15642)\u001b[0m [INFO] BaseAviary.__init__() loaded parameters from the drone's .urdf:\n",
      "\u001b[2m\u001b[36m(pid=15642)\u001b[0m [INFO] m 0.027000, L 0.039700,\n",
      "\u001b[2m\u001b[36m(pid=15642)\u001b[0m [INFO] ixx 0.000014, iyy 0.000014, izz 0.000022,\n",
      "\u001b[2m\u001b[36m(pid=15642)\u001b[0m [INFO] kf 0.000000, km 0.000000,\n",
      "\u001b[2m\u001b[36m(pid=15642)\u001b[0m [INFO] t2w 2.250000, max_speed_kmh 30.000000,\n",
      "\u001b[2m\u001b[36m(pid=15642)\u001b[0m [INFO] gnd_eff_coeff 11.368590, prop_radius 0.023135,\n",
      "\u001b[2m\u001b[36m(pid=15642)\u001b[0m [INFO] drag_xy_coeff 0.000001, drag_z_coeff 0.000001,\n",
      "\u001b[2m\u001b[36m(pid=15642)\u001b[0m [INFO] dw_coeff_1 2267.180000, dw_coeff_2 0.160000, dw_coeff_3 -0.110000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15642)\u001b[0m WARNING:tensorflow:From /home/mahendra/anaconda3/envs/TA/lib/python3.6/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=15642)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=15642)\u001b[0m Please use `layer.__call__` method instead.\n",
      "2021-03-24 20:07:37,895\tINFO trainable.py:102 -- Trainable.setup took 29.060 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2021-03-24 20:07:37,896\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "tr = MADDPGTrainer(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl1 = tr.get_policy(\"pol1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = observation_space.sample().reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.01323674, 0.2584071 , 0.24060018, 0.4355373 , 0.05221861]],\n",
       "       dtype=float32),\n",
       " [],\n",
       " {'action_dist_inputs': array([[-0.22037807,  0.06384001, -0.1733896 ,  0.24483114,  0.10656784]],\n",
       "        dtype=float32)})"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl1.compute_actions(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_workers': 4,\n",
       " 'num_envs_per_worker': 1,\n",
       " 'create_env_on_driver': False,\n",
       " 'rollout_fragment_length': 100,\n",
       " 'batch_mode': 'complete_episodes',\n",
       " 'num_gpus': 0,\n",
       " 'train_batch_size': 512,\n",
       " 'model': {'fcnet_hiddens': [256, 256],\n",
       "  'fcnet_activation': 'tanh',\n",
       "  'conv_filters': None,\n",
       "  'conv_activation': 'relu',\n",
       "  'free_log_std': False,\n",
       "  'no_final_linear': False,\n",
       "  'vf_share_layers': True,\n",
       "  'use_lstm': False,\n",
       "  'max_seq_len': 20,\n",
       "  'lstm_cell_size': 256,\n",
       "  'lstm_use_prev_action': False,\n",
       "  'lstm_use_prev_reward': False,\n",
       "  '_time_major': False,\n",
       "  'framestack': True,\n",
       "  'dim': 84,\n",
       "  'grayscale': False,\n",
       "  'zero_mean': True,\n",
       "  'custom_model': None,\n",
       "  'custom_model_config': {},\n",
       "  'custom_action_dist': None,\n",
       "  'custom_preprocessor': None,\n",
       "  'lstm_use_prev_action_reward': -1},\n",
       " 'optimizer': {},\n",
       " 'gamma': 0.99,\n",
       " 'horizon': None,\n",
       " 'soft_horizon': False,\n",
       " 'no_done_at_end': False,\n",
       " 'env_config': {'actions_are_logits': False},\n",
       " 'env': 'this-aviary-v0',\n",
       " 'normalize_actions': False,\n",
       " 'clip_rewards': None,\n",
       " 'clip_actions': True,\n",
       " 'preprocessor_pref': 'deepmind',\n",
       " 'lr': 0.0001,\n",
       " 'monitor': False,\n",
       " 'log_level': 'WARN',\n",
       " 'callbacks': __main__.FillInActions,\n",
       " 'ignore_worker_failures': False,\n",
       " 'log_sys_usage': True,\n",
       " 'fake_sampler': False,\n",
       " 'framework': 'tf',\n",
       " 'eager_tracing': False,\n",
       " 'explore': False,\n",
       " 'exploration_config': {'type': 'StochasticSampling'},\n",
       " 'evaluation_interval': None,\n",
       " 'evaluation_num_episodes': 10,\n",
       " 'in_evaluation': False,\n",
       " 'evaluation_config': {},\n",
       " 'evaluation_num_workers': 0,\n",
       " 'custom_eval_function': None,\n",
       " 'sample_async': False,\n",
       " '_use_trajectory_view_api': True,\n",
       " 'observation_filter': 'NoFilter',\n",
       " 'synchronize_filters': True,\n",
       " 'tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "  'inter_op_parallelism_threads': 8,\n",
       "  'gpu_options': {'allow_growth': True},\n",
       "  'log_device_placement': False,\n",
       "  'device_count': {'CPU': 1},\n",
       "  'allow_soft_placement': True},\n",
       " 'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "  'inter_op_parallelism_threads': 8},\n",
       " 'compress_observations': False,\n",
       " 'collect_metrics_timeout': 180,\n",
       " 'metrics_smoothing_episodes': 100,\n",
       " 'remote_worker_envs': False,\n",
       " 'remote_env_batch_wait_ms': 0,\n",
       " 'min_iter_time_s': 0,\n",
       " 'timesteps_per_iteration': 0,\n",
       " 'seed': None,\n",
       " 'extra_python_environs_for_driver': {},\n",
       " 'extra_python_environs_for_worker': {},\n",
       " 'num_cpus_per_worker': 1,\n",
       " 'num_gpus_per_worker': 0,\n",
       " 'custom_resources_per_worker': {},\n",
       " 'num_cpus_for_driver': 1,\n",
       " 'memory': 0,\n",
       " 'object_store_memory': 0,\n",
       " 'memory_per_worker': 0,\n",
       " 'object_store_memory_per_worker': 0,\n",
       " 'input': 'sampler',\n",
       " 'input_evaluation': ['is', 'wis'],\n",
       " 'postprocess_inputs': False,\n",
       " 'shuffle_buffer_size': 0,\n",
       " 'output': None,\n",
       " 'output_compress_columns': ['obs', 'new_obs'],\n",
       " 'output_max_file_size': 67108864,\n",
       " 'multiagent': {'policies': {'pol1': (ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy,\n",
       "    Box(-1.0, 1.0, (8,), float32),\n",
       "    Box(-1.0, 1.0, (5,), float32),\n",
       "    {'agent_id': 0}),\n",
       "   'pol2': (ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy,\n",
       "    Box(-1.0, 1.0, (8,), float32),\n",
       "    Box(-1.0, 1.0, (5,), float32),\n",
       "    {'agent_id': 1})},\n",
       "  'policy_mapping_fn': <function __main__.<lambda>(x)>,\n",
       "  'policies_to_train': None,\n",
       "  'observation_fn': None,\n",
       "  'replay_mode': 'lockstep'},\n",
       " 'logger_config': None,\n",
       " 'replay_sequence_length': 1,\n",
       " 'agent_id': 0,\n",
       " 'use_local_critic': False,\n",
       " 'use_state_preprocessor': False,\n",
       " 'actor_hiddens': [64, 64],\n",
       " 'actor_hidden_activation': 'relu',\n",
       " 'critic_hiddens': [64, 64],\n",
       " 'critic_hidden_activation': 'relu',\n",
       " 'n_step': 5,\n",
       " 'good_policy': 'maddpg',\n",
       " 'adv_policy': 'maddpg',\n",
       " 'buffer_size': 1000000,\n",
       " 'training_intensity': None,\n",
       " 'critic_lr': 0.005,\n",
       " 'actor_lr': 0.005,\n",
       " 'target_network_update_freq': 0,\n",
       " 'tau': 0.01,\n",
       " 'actor_feature_reg': 0.001,\n",
       " 'grad_norm_clipping': 0.5,\n",
       " 'learning_starts': 5120,\n",
       " 'before_learn_on_batch': <function ray.rllib.contrib.maddpg.maddpg.add_maddpg_postprocessing.<locals>.f(batch, workers, config)>,\n",
       " 'worker_index': 0}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl1.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_workers': 4,\n",
       " 'num_envs_per_worker': 1,\n",
       " 'create_env_on_driver': False,\n",
       " 'rollout_fragment_length': 100,\n",
       " 'batch_mode': 'complete_episodes',\n",
       " 'num_gpus': 0,\n",
       " 'train_batch_size': 512,\n",
       " 'model': {'fcnet_hiddens': [256, 256],\n",
       "  'fcnet_activation': 'tanh',\n",
       "  'conv_filters': None,\n",
       "  'conv_activation': 'relu',\n",
       "  'free_log_std': False,\n",
       "  'no_final_linear': False,\n",
       "  'vf_share_layers': True,\n",
       "  'use_lstm': False,\n",
       "  'max_seq_len': 20,\n",
       "  'lstm_cell_size': 256,\n",
       "  'lstm_use_prev_action': False,\n",
       "  'lstm_use_prev_reward': False,\n",
       "  '_time_major': False,\n",
       "  'framestack': True,\n",
       "  'dim': 84,\n",
       "  'grayscale': False,\n",
       "  'zero_mean': True,\n",
       "  'custom_model': None,\n",
       "  'custom_model_config': {},\n",
       "  'custom_action_dist': None,\n",
       "  'custom_preprocessor': None,\n",
       "  'lstm_use_prev_action_reward': -1},\n",
       " 'optimizer': {},\n",
       " 'gamma': 0.99,\n",
       " 'horizon': None,\n",
       " 'soft_horizon': False,\n",
       " 'no_done_at_end': False,\n",
       " 'env_config': {'actions_are_logits': False},\n",
       " 'env': 'this-aviary-v0',\n",
       " 'normalize_actions': False,\n",
       " 'clip_rewards': None,\n",
       " 'clip_actions': True,\n",
       " 'preprocessor_pref': 'deepmind',\n",
       " 'lr': 0.0001,\n",
       " 'monitor': False,\n",
       " 'log_level': 'WARN',\n",
       " 'callbacks': __main__.FillInActions,\n",
       " 'ignore_worker_failures': False,\n",
       " 'log_sys_usage': True,\n",
       " 'fake_sampler': False,\n",
       " 'framework': 'tf',\n",
       " 'eager_tracing': False,\n",
       " 'explore': False,\n",
       " 'exploration_config': {'type': 'StochasticSampling'},\n",
       " 'evaluation_interval': None,\n",
       " 'evaluation_num_episodes': 10,\n",
       " 'in_evaluation': False,\n",
       " 'evaluation_config': {},\n",
       " 'evaluation_num_workers': 0,\n",
       " 'custom_eval_function': None,\n",
       " 'sample_async': False,\n",
       " '_use_trajectory_view_api': True,\n",
       " 'observation_filter': 'NoFilter',\n",
       " 'synchronize_filters': True,\n",
       " 'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "  'inter_op_parallelism_threads': 2,\n",
       "  'gpu_options': {'allow_growth': True},\n",
       "  'log_device_placement': False,\n",
       "  'device_count': {'CPU': 1},\n",
       "  'allow_soft_placement': True},\n",
       " 'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "  'inter_op_parallelism_threads': 8},\n",
       " 'compress_observations': False,\n",
       " 'collect_metrics_timeout': 180,\n",
       " 'metrics_smoothing_episodes': 100,\n",
       " 'remote_worker_envs': False,\n",
       " 'remote_env_batch_wait_ms': 0,\n",
       " 'min_iter_time_s': 0,\n",
       " 'timesteps_per_iteration': 0,\n",
       " 'seed': None,\n",
       " 'extra_python_environs_for_driver': {},\n",
       " 'extra_python_environs_for_worker': {},\n",
       " 'num_cpus_per_worker': 1,\n",
       " 'num_gpus_per_worker': 0,\n",
       " 'custom_resources_per_worker': {},\n",
       " 'num_cpus_for_driver': 1,\n",
       " 'memory': 0,\n",
       " 'object_store_memory': 0,\n",
       " 'memory_per_worker': 0,\n",
       " 'object_store_memory_per_worker': 0,\n",
       " 'input': 'sampler',\n",
       " 'input_evaluation': ['is', 'wis'],\n",
       " 'postprocess_inputs': False,\n",
       " 'shuffle_buffer_size': 0,\n",
       " 'output': None,\n",
       " 'output_compress_columns': ['obs', 'new_obs'],\n",
       " 'output_max_file_size': 67108864,\n",
       " 'multiagent': {'policies': {'pol1': (ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy,\n",
       "    Box(-1.0, 1.0, (8,), float32),\n",
       "    Box(-1.0, 1.0, (5,), float32),\n",
       "    {'agent_id': 0}),\n",
       "   'pol2': (ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy,\n",
       "    Box(-1.0, 1.0, (8,), float32),\n",
       "    Box(-1.0, 1.0, (5,), float32),\n",
       "    {'agent_id': 1})},\n",
       "  'policy_mapping_fn': <function __main__.<lambda>(x)>,\n",
       "  'policies_to_train': None,\n",
       "  'observation_fn': None,\n",
       "  'replay_mode': 'lockstep'},\n",
       " 'logger_config': None,\n",
       " 'replay_sequence_length': 1,\n",
       " 'agent_id': None,\n",
       " 'use_local_critic': False,\n",
       " 'use_state_preprocessor': False,\n",
       " 'actor_hiddens': [64, 64],\n",
       " 'actor_hidden_activation': 'relu',\n",
       " 'critic_hiddens': [64, 64],\n",
       " 'critic_hidden_activation': 'relu',\n",
       " 'n_step': 5,\n",
       " 'good_policy': 'maddpg',\n",
       " 'adv_policy': 'maddpg',\n",
       " 'buffer_size': 1000000,\n",
       " 'training_intensity': None,\n",
       " 'critic_lr': 0.005,\n",
       " 'actor_lr': 0.005,\n",
       " 'target_network_update_freq': 0,\n",
       " 'tau': 0.01,\n",
       " 'actor_feature_reg': 0.001,\n",
       " 'grad_norm_clipping': 0.5,\n",
       " 'learning_starts': 5120,\n",
       " 'before_learn_on_batch': <function ray.rllib.contrib.maddpg.maddpg.add_maddpg_postprocessing.<locals>.f(batch, workers, config)>}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.12 64-bit ('TA': conda)",
   "language": "python",
   "name": "python361264bittacondab95bad1686664c54bb5a2af6325cd294"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
